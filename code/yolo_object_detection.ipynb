{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4REButZRtyxS",
        "outputId": "3192ad36-34a6-4b2c-cef6-238b37d625dd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CJz9OhXPs4hu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool, cpu_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4VT00Z3tJbx"
      },
      "source": [
        "# Load Data + YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RKX8mUwXD7mT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/landon/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-3-19 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24209MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "# load yolo\n",
        "def load_model():\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "    return model\n",
        "\n",
        "model = load_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/landon/Documents/Deep-Learning/DSAN6600Proj\n",
            "/home/landon/Documents/Deep-Learning/DSAN6600Proj/code\n"
          ]
        }
      ],
      "source": [
        "cwd = os.getcwd()\n",
        "parent = os.path.dirname(cwd)\n",
        "print(parent)\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/landon/Documents/Deep-Learning/DSAN6600Proj\n"
          ]
        }
      ],
      "source": [
        "#set parent as current working directory\n",
        "cwd = parent\n",
        "print(cwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VTPGkb77obj-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/landon/Documents/Deep-Learning/DSAN6600Proj/data/raw\n",
            "['/home/landon/Documents/Deep-Learning/DSAN6600Proj/data/raw/style_romanticism_index_73633.jpg', '/home/landon/Documents/Deep-Learning/DSAN6600Proj/data/raw/style_impressionism_index_35454.jpg', '/home/landon/Documents/Deep-Learning/DSAN6600Proj/data/raw/style_impressionism_index_34401.jpg']\n"
          ]
        }
      ],
      "source": [
        "project_path = cwd\n",
        "raw_imgs_path = os.path.join(project_path, 'data/raw')\n",
        "test_imgs_path = os.path.join(project_path, 'data/test-images')\n",
        "all_imgs = glob.glob(os.path.join(raw_imgs_path, '*.jpg'))\n",
        "test_imgs = glob.glob(os.path.join(test_imgs_path, '*.jpg'))\n",
        "\n",
        "### TESTING ON SUBSET ###\n",
        "#all_imgs = all_imgs[:200]\n",
        "batch_size = int(len(all_imgs) * 0.07)\n",
        "\n",
        "print(raw_imgs_path)\n",
        "print(all_imgs[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Rt0MhZzlPuDM"
      },
      "outputs": [],
      "source": [
        "def process_images(model, img_paths):\n",
        "    imgs = [Image.open(img_path).convert('RGB') for img_path in img_paths]\n",
        "    results = model(imgs)\n",
        "    dets = results.pandas().xyxy\n",
        "    people_det = [det[(det['class'] == 0) & (det['confidence'] >= 0.7)] for det in dets]\n",
        "    return people_det\n",
        "def worker(img_paths):\n",
        "    return process_images(model, img_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/landon/Documents/Deep-Learning/DSAN6600Proj/data/subjectbox\n"
          ]
        }
      ],
      "source": [
        "print(os.path.join(project_path, 'data/subjectbox'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JM7hydvJpAhV"
      },
      "outputs": [],
      "source": [
        "def crop_and_save(img_paths, detections_list, verbose=False):\n",
        "  out_path = os.path.join(project_path, 'data/subjectbox')\n",
        "  os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "  for img_path, detections in zip(img_paths, detections_list):\n",
        "    img = Image.open(img_path)\n",
        "    if detections.empty:\n",
        "      if verbose:\n",
        "        print(f\"No detections for {img_path}\")\n",
        "      continue\n",
        "\n",
        "    if verbose:\n",
        "      n_crops = len(detections)\n",
        "      plt.figure(figsize=(5 * max(1, n_crops), 6))\n",
        "      plt.subplot(1, n_crops + 1, 1)\n",
        "      plt.imshow(img)\n",
        "      plt.title('Original Image')\n",
        "      plt.axis('off')\n",
        "    i = 2\n",
        "\n",
        "    for index, row in detections.iterrows():\n",
        "      xmin, ymin, xmax, ymax = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
        "      cropped_img = img.crop((xmin, ymin, xmax, ymax))\n",
        "      img_name_no_ext = os.path.splitext(os.path.basename(img_path))[0]\n",
        "      new_img_name = f\"{img_name_no_ext}_subject_box_{xmin}_{ymin}_{xmax}_{ymax}.jpg\"\n",
        "      save_path = os.path.join(out_path, new_img_name)\n",
        "      cropped_img.save(save_path)\n",
        "\n",
        "      if verbose:\n",
        "        plt.subplot(1, n_crops + 1, i)\n",
        "        plt.imshow(cropped_img)\n",
        "        plt.title(f'Cropped {i-1}')\n",
        "        plt.axis('off')\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFJ4pQQnuCEX",
        "outputId": "63b8e57e-105c-41d8-f66b-79c60a60b717"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Process SpawnPoolWorker-10:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mnum_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m img_path, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch, pool\u001b[38;5;241m.\u001b[39mimap_unordered(worker, [batch])):\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m     20\u001b[0m                 crop_and_save(img_path, result)\n",
            "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
            "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import logging\n",
        "from multiprocessing import Pool, set_start_method\n",
        "import torch\n",
        "\n",
        "# Ensure the start method is 'spawn'\n",
        "set_start_method('spawn', force=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s - %(levelname)s')\n",
        "\n",
        "# Assuming test_imgs is defined and worker, crop_and_save functions are implemented properly\n",
        "batch_size = 500\n",
        "batches = [test_imgs[i:i + batch_size] for i in range(0, len(test_imgs), batch_size)]\n",
        "num_processes = 4\n",
        "\n",
        "with Pool(processes=num_processes) as pool:\n",
        "    for batch in batches:\n",
        "        for img_path, result in zip(batch, pool.imap_unordered(worker, [batch])):\n",
        "            if result:\n",
        "                crop_and_save(img_path, result)\n",
        "            else:\n",
        "                print(\"No detections for this image:\", img_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
