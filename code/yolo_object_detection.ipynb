{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4REButZRtyxS",
        "outputId": "3192ad36-34a6-4b2c-cef6-238b37d625dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CJz9OhXPs4hu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool, cpu_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4VT00Z3tJbx"
      },
      "source": [
        "# Load Data + YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RKX8mUwXD7mT"
      },
      "outputs": [],
      "source": [
        "# load yolo\n",
        "def load_model():\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "VTPGkb77obj-"
      },
      "outputs": [],
      "source": [
        "project_path = '/content/drive/MyDrive/Grad/DSAN6600/proj/'\n",
        "raw_imgs_path = os.path.join(project_path, 'data/raw')\n",
        "all_imgs = glob.glob(os.path.join(raw_imgs_path, '*.jpg'))\n",
        "\n",
        "### TESTING ON SUBSET ###\n",
        "#all_imgs = all_imgs[:200]\n",
        "batch_size = int(len(all_imgs) * 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Rt0MhZzlPuDM"
      },
      "outputs": [],
      "source": [
        "def load_and_process_imgs(img_paths):\n",
        "  model = load_model()\n",
        "  imgs = [Image.open(img_path) for img_path in img_paths]\n",
        "  results = model(imgs)\n",
        "  dets = results.pandas().xyxy\n",
        "  people_det = [det[(det['class'] == 0) & (det['confidence'] >= 0.5)] for det in dets]\n",
        "  return people_det\n",
        "\n",
        "def worker(img_paths):\n",
        "  return load_and_process_imgs(img_paths)\n",
        "\n",
        "def create_batches(img_paths, batch_size):\n",
        "  return [img_paths[i:i + batch_size] for i in range(0, len(img_paths), batch_size)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JM7hydvJpAhV"
      },
      "outputs": [],
      "source": [
        "def crop_and_save(img_paths, detections_list, verbose=False):\n",
        "  out_path = os.path.join(project_path, 'data/subjectbox')\n",
        "  os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "  for img_path, detections in zip(img_paths, detections_list):\n",
        "    img = Image.open(img_path)\n",
        "    if detections.empty:\n",
        "      if verbose:\n",
        "        print(f\"No detections for {img_path}\")\n",
        "      continue\n",
        "\n",
        "    if verbose:\n",
        "      n_crops = len(detections)\n",
        "      plt.figure(figsize=(5 * max(1, n_crops), 6))\n",
        "      plt.subplot(1, n_crops + 1, 1)\n",
        "      plt.imshow(img)\n",
        "      plt.title('Original Image')\n",
        "      plt.axis('off')\n",
        "    i = 2\n",
        "\n",
        "    for index, row in detections.iterrows():\n",
        "      xmin, ymin, xmax, ymax = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
        "      cropped_img = img.crop((xmin, ymin, xmax, ymax))\n",
        "      img_name_no_ext = os.path.splitext(os.path.basename(img_path))[0]\n",
        "      new_img_name = f\"{img_name_no_ext}_subject_box_{xmin}_{ymin}_{xmax}_{ymax}.jpg\"\n",
        "      save_path = os.path.join(out_path, new_img_name)\n",
        "      cropped_img.save(save_path)\n",
        "\n",
        "      if verbose:\n",
        "        plt.subplot(1, n_crops + 1, i)\n",
        "        plt.imshow(cropped_img)\n",
        "        plt.title(f'Cropped {i-1}')\n",
        "        plt.axis('off')\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFJ4pQQnuCEX",
        "outputId": "63b8e57e-105c-41d8-f66b-79c60a60b717"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2024-4-16 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "batch_data = create_batches(all_imgs, batch_size)\n",
        "cpu_count = 2 # UPDATE ACCORDINGLY\n",
        "\n",
        "with Pool(processes=cpu_count) as pool:\n",
        "  for result, batch_paths in zip(pool.imap_unordered(worker, batch_data), batch_data):\n",
        "    if not result:\n",
        "      print(\"No detections in this batch:\", batch_paths)\n",
        "      continue\n",
        "    crop_and_save(batch_paths, result, verbose=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
